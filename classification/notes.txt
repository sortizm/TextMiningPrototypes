# 4 secs 1 file
# 1 minute 61 files (one category)
                words_in_file = sorted(corpus.words(fid))
                sample = [0] * len(all_words)
                last_word = None
                last_index = None
                for word in sorted(words_in_file):
                    if word not in all_words:
                        continue
                    if word != last_word:
                        last_word = word
                        last_index = all_words.index(last_word)
                    sample[last_index] += 1
                samples.append(tuple(sample))

# 0.155 secs 1 file
# 3.5 sec 61 files (one brown category)
# 48 secs 500 files (entire brown corpus)
                count = Counter(corpus.words(fid))
                samples.append(tuple(count[word] for word in all_words))

********************************************************************************
********************************************************************************

get_all_words: 39574 words
get_all_words_stemmed: 24334 words

diff: 15240 words

# 28 seconds to run on brown corpus
def get_all_words_stemmed():
    stemmer = snowball.EnglishStemmer(ignore_stopwords=True)
    all_words = sorted(list(
            set(stemmer.stem(w.lower()) for w in corpus.words() if w.isalnum() and len(w) > 3) -
            set(stopwords.words())
            ))
    return all_words

# 8 seconds to run on brown corpus
def get_all_words():
    all_words = sorted(list(
            set(w.lower() for w in corpus.words() if w.isalnum() and len(w) > 3) -
            set(stopwords.words())
            ))
    return all_words
